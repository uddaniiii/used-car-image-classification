import shutil
import os
from collections import defaultdict
import hashlib

# 1. ì›ë³¸ train í´ë” â†’ ìƒˆ í´ë”ë¡œ ë³µì‚¬
src_train_dir = 'data/train'
backup_train_dir = 'data/train_no_duplicates'

if not os.path.exists(backup_train_dir):
    shutil.copytree(src_train_dir, backup_train_dir)
    print(f"âœ… '{src_train_dir}' í´ë”ë¥¼ '{backup_train_dir}'ë¡œ ë³µì‚¬ ì™„ë£Œ")
else:
    print(f"âš ï¸ '{backup_train_dir}' í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì¤‘ë³µ ì œê±° ì‘ì—… ì§„í–‰í•©ë‹ˆë‹¤.")

# 2. ìƒˆ í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚° ë° ì¤‘ë³µ íƒì§€
hash_to_paths = defaultdict(list)

for root, dirs, files in os.walk(backup_train_dir):
    for file in files:
        if file.endswith(('.jpg', '.jpeg', '.png')):
            file_path = os.path.join(root, file)
            with open(file_path, 'rb') as f:
                img_hash = hashlib.md5(f.read()).hexdigest()
            hash_to_paths[img_hash].append(file_path)

# 3. ì¤‘ë³µ ì´ë¯¸ì§€ ì œê±° (ì²«ë²ˆì§¸ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ)
dup_count = 0
for paths in hash_to_paths.values():
    if len(paths) > 1:
        # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì œì™¸í•˜ê³  ì‚­ì œ
        for dup_path in paths[1:]:
            os.remove(dup_path)
            dup_count += 1

print(f"ğŸ—‘ï¸ ì¤‘ë³µ ì´ë¯¸ì§€ ì´ {dup_count}ê°œ ì œê±° ì™„ë£Œ")
