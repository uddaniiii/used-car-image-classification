import argparse
import os
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import pandas as pd
import albumentations as A
from albumentations.pytorch import ToTensorV2
from dataset import CustomImageDataset
import config
from transforms import get_transforms
from model import BaseModel, TimmModel
from utils import seed_everything, load_class_names
from tqdm import tqdm
import numpy as np  # npy ì €ì¥ìš©

def parse_args():
    parser = argparse.ArgumentParser(description="used-car-image-classification")
    parser.add_argument("--weight_path", type=str, required=True, help="í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ")
    parser.add_argument("--output_csv", type=str, default=config.OUTPUT_CSV, help="ì¶œë ¥ ì œì¶œ íŒŒì¼ëª…")
    parser.add_argument("--output_npy", type=str, default=config.OUTPUT_NPY, help="í™•ë¥ ê°’ npy ì €ì¥ ê²½ë¡œ (ì˜µì…˜)")
    parser.add_argument("--img_size", type=int, default=config.IMG_SIZE)
    parser.add_argument("--batch_size", type=int, default=64, help="ë°°ì¹˜ ì‚¬ì´ì¦ˆ")
    parser.add_argument("--seed", type=int, default=42, help="ì‹œë“œ")
    return parser.parse_args()

def main():
    args = parse_args()

    seed_everything(args.seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    class_names = load_class_names('./classes.txt')

    train_transform, val_transform = get_transforms(args.img_size)
    test_dataset = CustomImageDataset(config.TEST_DIR, transform=val_transform, is_test=True)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)

    model = TimmModel(model_name=config.MODEL_NAME, num_classes=len(class_names)).to(device)
    model.load_state_dict(torch.load(args.weight_path, map_location=device))
    model.to(device)
    model.eval()

    results = []
    all_probs = []

    with torch.no_grad():
        for images in tqdm(test_loader, desc="Inference Progress"):
            images = images.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)

            all_probs.append(probs.cpu().numpy())

            # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            for prob in probs.cpu():  # prob: (num_classes,)
                result = {
                    class_names[i]: prob[i].item()
                    for i in range(len(class_names))
                }
                results.append(result)

    pred = pd.DataFrame(results)

    submission = pd.read_csv('./data/sample_submission.csv', encoding='utf-8-sig')
    class_columns = submission.columns[1:]
    pred = pred[class_columns]

    submission[class_columns] = pred.values
    submission.to_csv(args.output_csv, index=False, encoding='utf-8-sig')

    print(f"âœ… Inference ì™„ë£Œ. í™•ë¥  ê¸°ë°˜ ê²°ê³¼ ì €ì¥ë¨: {args.output_csv}")

    # npy ì €ì¥ ì˜µì…˜ì´ ìˆì„ ë•Œ ì €ì¥
    if args.output_npy:
        all_probs_array = np.concatenate(all_probs, axis=0)
        print("ğŸ” npy ì €ì¥ shape:", all_probs_array.shape)  # ğŸ‘ˆ ì¶”ê°€
        np.save(args.output_npy, all_probs_array)
        print(f"âœ… í™•ë¥ ê°’ npy íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {args.output_npy}")
        
if __name__ == "__main__":
    main()
